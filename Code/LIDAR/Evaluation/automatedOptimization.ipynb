{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, different variable values can be tested programmatically, to increase a score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tf.transformations import euler_from_quaternion, euler_matrix\n",
    "import ros_numpy\n",
    "import pcl\n",
    "import time\n",
    "import numpy as np\n",
    "import math\n",
    "import rosbag\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bag_path = '/home/user/rosbags/big/hdl_slam_validation/2021-10-07-08-32-58.bag'\n",
    "# Load rosbag\n",
    "bag = rosbag.Bag(bag_path)\n",
    "\n",
    "# Extract data from hdl bag\n",
    "# Contains raw lidar data and the position/orientation of car\n",
    "pose = []\n",
    "for topic, msg, t in bag.read_messages(topics='/odom'):\n",
    "    pose.append(msg.pose.pose)\n",
    "lidar = []\n",
    "for topic, msg, t in bag.read_messages(topics='/rslidar_points'):\n",
    "    lidar.append(msg)\n",
    "\n",
    "# To synchronize both topics, remove first of odom and the last 2 of rslidar\n",
    "pose = pose[1:]\n",
    "lidar = lidar[:-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# My ROS Node\n",
    "class VisualDetection():\n",
    "\n",
    "    def __init__(self, ransac_distance_thresh=0.017, ransac_weight=0.125, ransac_make_seg=50,\n",
    "    voxel_leaf=0.1, plane_near_ground=0.8, cut=[0, 30, -3.5, 3.5, -1, 1.5], max_iter=4,\n",
    "    min_points=100):\n",
    "        self.distance_threshold = ransac_distance_thresh\n",
    "        self.distance_weight = ransac_weight\n",
    "        self.ransac_make_segmenter_normals = ransac_make_seg\n",
    "        self.plane_near_ground = plane_near_ground\n",
    "        self.cut = cut\n",
    "        self.min_points = min_points\n",
    "        self.max_iterations = max_iter\n",
    "        self.voxel_leaf = voxel_leaf\n",
    "\n",
    "    def spin(self, cloud, pose):\n",
    "        self.cloud = cloud\n",
    "        self.pose = pose\n",
    "        # Convert PointCloud2 msg to numpy array\n",
    "        pc_array = ros_numpy.point_cloud2.pointcloud2_to_xyz_array(self.cloud, remove_nans=True)\n",
    "        # Apply lidar to car frame transformation\n",
    "        pc_array_tf = self.transform_pc(pc_array, roll=0, pitch=25.53, yaw=0)\n",
    "        # Filter unwanted points (to reduce point cloud size) with passthrough filter\n",
    "        pc_array_cut = self.reduce_pc(pc_array_tf, self.cut)\n",
    "        # Convert numpy array to pcl object\n",
    "        pc_cut = pcl.PointCloud()\n",
    "        pc_cut.from_array(pc_array_cut.astype('float32'))\n",
    "        # Downsample point cloud using voxel filter to further decrease size\n",
    "        pc_small = self.voxel_filter(pc_cut, self.voxel_leaf)\n",
    "        # Perform RANSAC until no new planes are being detected\n",
    "        plane_coor, data = self.plane_detection(pc_small, self.min_points, self.max_iterations)\n",
    "        return plane_coor, data\n",
    "\n",
    "    def transform_pc(self, pc, roll=0, pitch=0, yaw=0, transl_x=1.753, transl_y=0, transl_z=1.156):\n",
    "        \"\"\"Transformation from Lidar frame to car frame. Rotation in rad and translation in m.\"\"\"\n",
    "        # Rotation matrix\n",
    "        rot = euler_matrix(roll, pitch, yaw, 'sxyz')[:3, :3]\n",
    "        # Apply rotation\n",
    "        pc_tf = np.inner(pc, rot)\n",
    "        # Translation\n",
    "        translation = [transl_x, transl_y, transl_z]\n",
    "        # Combine rotation and translation\n",
    "        pc_tf += translation\n",
    "        return pc_tf\n",
    "\n",
    "    def reduce_pc(self, pc, cut):\n",
    "        \"\"\"Removes points outside of box\"\"\"\n",
    "        x_lower, x_upper, y_lower, y_upper, z_lower, z_upper = cut\n",
    "        pc_cut = pc[(pc[:, 0] > x_lower) & (pc[:, 0] < x_upper) & (pc[:, 1] > y_lower) & (\n",
    "            pc[:, 1] < y_upper) & (pc[:, 2] > z_lower) & (pc[:, 2] < z_upper)]\n",
    "        return pc_cut\n",
    "\n",
    "    def voxel_filter(self, pc, leaf_size):\n",
    "        \"\"\"Downsample point cloud using voxel filter\"\"\"\n",
    "        vg = pc.make_voxel_grid_filter()\n",
    "        # Leaf_size is the length of the side of the voxel cube in m\n",
    "        vg.set_leaf_size(leaf_size, leaf_size, leaf_size)\n",
    "        pc_filtered = vg.filter()\n",
    "        # print('Reduced size from {} to {}'.format(pc.size, pc_filtered.size))\n",
    "        return pc_filtered\n",
    "\n",
    "    def plane_detection(self, pc, min_points, max_planes):\n",
    "        \"\"\"Detects all planes in point cloud\"\"\"\n",
    "        # Ground vector\n",
    "        g_vec = None\n",
    "        counter = 0\n",
    "        while pc.size > min_points and counter < max_planes:\n",
    "            # Detect most dominate plane and get inliers and normal vector\n",
    "            indices, coefficients = self.ransac(pc)\n",
    "            n_vec = coefficients[:-1]\n",
    "\n",
    "            # Split pointcloud in inliers and outliers of plane\n",
    "            pc, plane, pc_points = self.split_pc(pc, indices)\n",
    "\n",
    "            # Exit if plane is empty\n",
    "            if not plane:\n",
    "                return [], []\n",
    "\n",
    "            # Ignore walls to the side or in front\n",
    "            if self.is_plane_near_ground(n_vec, self.plane_near_ground):\n",
    "                # First ground like detection is most probably the ground\n",
    "                if g_vec is None:\n",
    "                    g_vec = n_vec\n",
    "                # Either ground is detected again or potential ramp\n",
    "                else:\n",
    "                    is_ramp, data = self.ramp_detection(plane, g_vec, n_vec, 4, 7, 0, 5, 2, 4, 0, 10)\n",
    "                    if is_ramp:\n",
    "                        # Transform plane from local rslidar coordinates to global map coordinates\n",
    "                        plane_global = self.relative_to_absolute(plane)\n",
    "                        return plane_global, data\n",
    "                    else:  \n",
    "                        continue\n",
    "            counter += 1\n",
    "        return [], []\n",
    "\n",
    "    def relative_to_absolute(self, pc):\n",
    "        \"\"\"Transforms relative lidar data to absolute by adding translation rotating\"\"\"\n",
    "        # pc_arr = pc.to_array()\n",
    "        pc_arr = np.array(pc)\n",
    "        # Odometer\n",
    "        pos = self.pose.position\n",
    "        translation = [pos.x, pos.y, pos.z]\n",
    "        ori = self.pose.orientation\n",
    "        quat = [ori.x, ori.y, ori.z, ori.w]\n",
    "        roll, pitch, yaw = euler_from_quaternion(quat)\n",
    "        # Rotation matrix\n",
    "        rot = euler_matrix(roll, pitch, yaw, 'sxyz')[:3, :3]\n",
    "        # Apply rotation\n",
    "        pc_tf = np.inner(pc_arr, rot)\n",
    "        # Combine rotation and translation\n",
    "        pc_tf += translation\n",
    "        return pc_tf\n",
    "\n",
    "    def ramp_detection(\n",
    "            self, plane, g_vec, n_vec, min_angle, max_angle, \n",
    "            min_height, max_height, min_width, max_width, \n",
    "            min_length, max_length, logging=False):\n",
    "        \"\"\"Checks if conditions to be considered a ramp are fullfilled.\"\"\"\n",
    "        # Convert pcl plane to numpy array\n",
    "        plane_array = np.array(plane)\n",
    "        # Calculate angle [deg] between new and previously recorded normal vector of ground\n",
    "        angle = self.angle_calc(g_vec, n_vec)\n",
    "        # Get ramp height (Difference between z-values of furthest and nearest point)\n",
    "        height = max(plane_array[:, 2]) - min(plane_array[:, 2])\n",
    "        # Get ramp width (Difference between y-values)\n",
    "        width = max(plane_array[:, 1]) - min(plane_array[:, 1])\n",
    "        # Length in x direction \n",
    "        x = max(plane_array[:, 0]) - min(plane_array[:, 0])\n",
    "        # Get ramp length (using pythagorean theorem)\n",
    "        length = math.sqrt(x**2 + height**2)\n",
    "        # Ramp distance (x-value of nearest point of the plane)\n",
    "        dist = min(plane_array[:,0])\n",
    "        data = [angle, dist, width, length, height]\n",
    "        if min_angle <= angle <= max_angle:\n",
    "            pass\n",
    "        else:\n",
    "            return False, data\n",
    "        if min_height <= height <= max_height:\n",
    "            pass\n",
    "        else:\n",
    "            return False, data\n",
    "        if min_width <= width <= max_width:\n",
    "            pass\n",
    "        else:\n",
    "            return False, data\n",
    "        if min_length <= length <= max_length:\n",
    "            pass\n",
    "        else:\n",
    "            return False, data\n",
    "        return True, data\n",
    "\n",
    "    def ransac(self, pc):\n",
    "        \"\"\"Finds inliers and normal vector of dominant plane\"\"\"\n",
    "        # 50?\n",
    "        seg = pc.make_segmenter_normals(self.ransac_make_segmenter_normals)\n",
    "        # Doubles the speed if True\n",
    "        seg.set_optimize_coefficients(True)\n",
    "        seg.set_model_type(pcl.SACMODEL_NORMAL_PLANE)\n",
    "        seg.set_method_type(pcl.SAC_RANSAC)\n",
    "        # How close a point must be to model to be considered inlier\n",
    "        seg.set_distance_threshold(self.distance_threshold)\n",
    "        # normal_distance_weight?\n",
    "        seg.set_normal_distance_weight(self.distance_weight)\n",
    "        # How many tries\n",
    "        seg.set_max_iterations(100)\n",
    "        indices, coefficients = seg.segment()\n",
    "        return indices, coefficients\n",
    "\n",
    "    def split_pc(self, pc, inliers):\n",
    "        \"\"\"Extract detected plane from point cloud and split into two pcs\"\"\"\n",
    "        # Get point cooridnates of plane\n",
    "        detected_plane = [pc[i] for i in inliers]\n",
    "        # Point cloud of detected plane (inliers)\n",
    "        pc_inliers = pc.extract(inliers)\n",
    "        # Point cloud of outliers\n",
    "        outlier_indices = list(set(np.arange(pc.size)).symmetric_difference(inliers))\n",
    "        pc_outliers = pc.extract(outlier_indices)\n",
    "        return pc_outliers, detected_plane, pc_inliers\n",
    "\n",
    "    def is_plane_near_ground(self, v, threshold=0.8):\n",
    "        \"\"\"Returns True if plane is on the ground (and false if e.g. side wall)\"\"\"\n",
    "        return abs(v[2]) > threshold   \n",
    "\n",
    "    def angle_calc(self, v1, v2, degrees=True):\n",
    "        \"\"\"Calculate angle between two vectors (planes)\"\"\"\n",
    "        # Assuming both vectors can be rotated alongside one axis to be aligned\n",
    "        dot = np.dot(v1, v2)\n",
    "        if dot <= 1:\n",
    "            angle = np.arccos(dot)\n",
    "        else:\n",
    "            angle = 0\n",
    "        if degrees is True:\n",
    "            return np.degrees(angle)\n",
    "        else:\n",
    "            return angle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dumb_optimizer(varIndex, start, end, steps=6, visualize=True):\n",
    "    # Variables that can be changed\n",
    "    var_names = ['ransac_distance_thresh', 'ransac_weight', 'ransac_make_seg',\n",
    "        'voxel_leaf', 'plane_near_ground', 'max_iter', 'min_points', 'cut']\n",
    "    # Standard parameters\n",
    "    params = [0.017, 0.125, 50, 0.1, 0.8, 4, 100, [0, 30, -3.5, 3.5, -1, 1.5]]\n",
    "    # List for visualization\n",
    "    vis_list = []\n",
    "    # Change parameter value every run\n",
    "    for var_val in np.linspace(start, end, steps):\n",
    "        # Adjust input parameter\n",
    "        params[varIndex] = var_val\n",
    "        # Create instance of class\n",
    "        vd = VisualDetection(ransac_distance_thresh=params[0], ransac_weight=params[1], \n",
    "        ransac_make_seg=params[2], voxel_leaf=params[3], plane_near_ground=params[4], \n",
    "        max_iter=params[5], min_points=params[6], cut=params[7])\n",
    "        # Lists to fill, will contain entry for each plane\n",
    "        planes = []\n",
    "        ramp_stats = []\n",
    "        # Timestop\n",
    "        start_t = time.time()\n",
    "        for i in range(len(lidar)):\n",
    "            plane_points, data = vd.spin(lidar[i], pose[i])\n",
    "            planes.append(plane_points)\n",
    "            ramp_stats.append(data)\n",
    "        # Timestop end\n",
    "        runtime = time.time() - start_t\n",
    "\n",
    "        # Remove empty lists (when no ramp has been detected)\n",
    "        ramp_arrays = [x for x in planes if x != []]\n",
    "        ramp_stats = [x for x in ramp_stats if x != []]\n",
    "\n",
    "        # Convert list to dictionary\n",
    "        dic = []\n",
    "        for i, arr in enumerate(ramp_arrays):\n",
    "            for j, point in enumerate(arr):\n",
    "                dic.append(\n",
    "                    {\n",
    "                        'sampleIdx': i,\n",
    "                        'pointIdx': j,\n",
    "                        'x': point[0],\n",
    "                        'y': point[1],\n",
    "                        'z': point[2]\n",
    "                    }\n",
    "                )\n",
    "        # And finally to pandas Dataframe\n",
    "        df = pd.DataFrame(dic)\n",
    "        # Adjust column order\n",
    "        df = df[['sampleIdx', 'pointIdx', 'x', 'y', 'z']]\n",
    "\n",
    "        # Ground truth coordinates of ramp (measured by using globalmap points)\n",
    "        x_range = [-21, -9]\n",
    "        y_range = [35, 39] \n",
    "\n",
    "        # Check if a point lies within ramp region\n",
    "        lies_inside = []\n",
    "        for i,x in enumerate(df['x']):\n",
    "            if x_range[0] < x < x_range[1]:\n",
    "                if y_range[0] < df['y'][i] < y_range[1]:\n",
    "                    # True if x and y coordinate inside region\n",
    "                    lies_inside.append(True)\n",
    "                else:\n",
    "                    lies_inside.append(False)\n",
    "            else:\n",
    "                lies_inside.append(False)\n",
    "        # Add column (if point lies in region) to data frame\n",
    "        df['inlier'] = lies_inside\n",
    "\n",
    "        # Calculate how many points of each sample lie in ramp region\n",
    "        true_inliers = []\n",
    "        samples_num = df.sampleIdx.max() + 1\n",
    "        for i in range(samples_num):\n",
    "            # Bool list of inliers and outliers of sample\n",
    "            bool_lst = df[df['sampleIdx'] == i]['inlier']\n",
    "            # Percentage of inliers of sample\n",
    "            true_inliers.append(sum(bool_lst) / float(len(bool_lst)))\n",
    "\n",
    "        # Average percentage of points in ramp region per sample\n",
    "        score = np.array(true_inliers).mean()\n",
    "        print('With parameter {} = {} the score was {:05.2f}% with a runtime of {:05.2f}s'.format(\n",
    "            var_names[varIndex], var_val, score*100, runtime))\n",
    "        # Todo: Add expected value of ramp (sth like time from when ramp is visible\n",
    "        # Todo: until not times the rate)\n",
    "        print('Out of ... expected samples, {} were detected.'.format(len(true_inliers)))\n",
    "        vis_list.append([var_names[varIndex], var_val, score*100, runtime])\n",
    "    if visualize:\n",
    "        df = pd.DataFrame(vis_list)\n",
    "        fig = make_subplots(rows=1, cols=2, \n",
    "        subplot_titles=('Score (higher is better)', 'Runtime (lower is better)'),\n",
    "        y_title='Parameter value')\n",
    "        fig.add_trace(go.Bar(\n",
    "            y = df.iloc[:,1], x=df.iloc[:,2],\n",
    "            name=\"Score\",\n",
    "            orientation='h', \n",
    "            textposition='inside'\n",
    "        ))\n",
    "        fig.add_trace(go.Bar(\n",
    "            y = df.iloc[:,1], x=df.iloc[:,3],\n",
    "            name=\"Runtime\",\n",
    "            orientation='h', \n",
    "            marker_color='orange',\n",
    "            textposition='inside'\n",
    "        ), row=1, col=2)\n",
    "        fig.update_traces(texttemplate='%{y:.3f}', insidetextanchor=\"middle\")\n",
    "        fig.update_xaxes(title_text=\"Percentage [%]\", row=1, col=1)\n",
    "        fig.update_xaxes(title_text=\"Time [s]\", row=1, col=2)\n",
    "        fig.update_layout(title_text=\"Performance for different \" + vis_list[0][0] + \" values\")\n",
    "        fig.show()\n",
    "        return fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following parameters can be tested (standard value on right hand side):\n",
    "\n",
    "0. ransac_distance_thresh=0.017\n",
    "1. ransac_weight=0.125\n",
    "2. ransac_make_seg=50,\n",
    "3. voxel_leaf=0.1\n",
    "4. plane_near_ground=0.8\n",
    "5. cut=[0, 30, -3.5, 3.5, -1, 1.5]\n",
    "6. max_iter=4\n",
    "7. min_points=100\n",
    "\n",
    "The optimizer takes the following input:\n",
    "\n",
    "`def dumb_optimizer(varIndex, start, end, steps=6)`\n",
    "\n",
    "The score and runtime are displayed in the following plots.\n",
    "\n",
    "The score is calculated as the average value of inlier percentage per detected plane, that is considered a ramp. Hence it is also possible to get a perfect score of 100%, while only one plane was detected. To tackle this problem, another plot was created further down, which shows the ratio and count of true positives and false positives.\n",
    "\n",
    "The best way to evaluate would be to set a constant number of positives manually. E.g. if the car is 20m in front of a ramp it should be able to detect it, until the lower threshold has been reached, e.g. 5m before the ramp, at which the lidar can not distinguish between ground and ramp anymore.\n",
    "\n",
    "Because right now the amount of positives changes for each sample / parameter change, which is not good."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With parameter ransac_weight = 0.125 the score was 81.05% with a runtime of 12.66s\n",
      "Out of ... expected samples, 69 were detected.\n"
     ]
    }
   ],
   "source": [
    "# Standard parameters\n",
    "params = [0.017, 0.125, 50, 0.1, 0.8, 4, 100, [0, 30, -3.5, 3.5, -1, 1.5]]\n",
    "# Change each parameter by 50 to 100% and explore their influence\n",
    "for i in range(7):\n",
    "    if i != 4:\n",
    "        dumb_optimizer(i, params[i]*0.5, params[i]*2, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now visualize the number of true positives and false positives instead of the score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dumb_optimizer2(varIndex, start, end, steps=6, visualize=True):\n",
    "    # Variables that can be changed\n",
    "    var_names = ['ransac_distance_thresh', 'ransac_weight', 'ransac_make_seg',\n",
    "        'voxel_leaf', 'plane_near_ground', 'max_iter', 'min_points', 'cut']\n",
    "    # Standard parameters\n",
    "    params = [0.017, 0.125, 50, 0.1, 0.8, 4, 100, [0, 30, -3.5, 3.5, -1, 1.5]]\n",
    "    # List for visualization\n",
    "    vis_list = []\n",
    "    # Change parameter value every run\n",
    "    for var_val in np.linspace(start, end, steps):\n",
    "        # Adjust input parameter\n",
    "        params[varIndex] = var_val\n",
    "        # Create instance of class\n",
    "        vd = VisualDetection(ransac_distance_thresh=params[0], ransac_weight=params[1], \n",
    "        ransac_make_seg=params[2], voxel_leaf=params[3], plane_near_ground=params[4], \n",
    "        max_iter=params[5], min_points=params[6], cut=params[7])\n",
    "        # Lists to fill, will contain entry for each plane\n",
    "        planes = []\n",
    "        ramp_stats = []\n",
    "        # Timestop\n",
    "        start_t = time.time()\n",
    "        for i in range(len(lidar)):\n",
    "            plane_points, data = vd.spin(lidar[i], pose[i])\n",
    "            planes.append(plane_points)\n",
    "            ramp_stats.append(data)\n",
    "        # Timestop end\n",
    "        runtime = time.time() - start_t\n",
    "\n",
    "        # Remove empty lists (when no ramp has been detected)\n",
    "        ramp_arrays = [x for x in planes if x != []]\n",
    "        ramp_stats = [x for x in ramp_stats if x != []]\n",
    "\n",
    "        # Convert list to dictionary\n",
    "        dic = []\n",
    "        for i, arr in enumerate(ramp_arrays):\n",
    "            for j, point in enumerate(arr):\n",
    "                dic.append(\n",
    "                    {\n",
    "                        'sampleIdx': i,\n",
    "                        'pointIdx': j,\n",
    "                        'x': point[0],\n",
    "                        'y': point[1],\n",
    "                        'z': point[2]\n",
    "                    }\n",
    "                )\n",
    "        # And finally to pandas Dataframe\n",
    "        df = pd.DataFrame(dic)\n",
    "        # Adjust column order\n",
    "        df = df[['sampleIdx', 'pointIdx', 'x', 'y', 'z']]\n",
    "\n",
    "        # Ground truth coordinates of ramp (measured by using globalmap points)\n",
    "        x_range = [-21, -9]\n",
    "        y_range = [35, 39] \n",
    "\n",
    "        # Check if a point lies within ramp region\n",
    "        lies_inside = []\n",
    "        for i,x in enumerate(df['x']):\n",
    "            if x_range[0] < x < x_range[1]:\n",
    "                if y_range[0] < df['y'][i] < y_range[1]:\n",
    "                    # True if x and y coordinate inside region\n",
    "                    lies_inside.append(True)\n",
    "                else:\n",
    "                    lies_inside.append(False)\n",
    "            else:\n",
    "                lies_inside.append(False)\n",
    "        # Add column (if point lies in region) to data frame\n",
    "        df['inlier'] = lies_inside\n",
    "\n",
    "        # Calculate how many points of each sample lie in ramp region\n",
    "        true_inliers = []\n",
    "        samples_num = df.sampleIdx.max() + 1\n",
    "        for i in range(samples_num):\n",
    "            # Bool list of inliers and outliers of sample\n",
    "            bool_lst = df[df['sampleIdx'] == i]['inlier']\n",
    "            # Percentage of inliers of sample\n",
    "            true_inliers.append(sum(bool_lst) / float(len(bool_lst)))\n",
    "\n",
    "        # Average percentage of points in ramp region per sample\n",
    "        score = np.array(true_inliers).mean()\n",
    "        print('With parameter {} = {} the score was {:05.2f}% with a runtime of {:05.2f}s'.format(\n",
    "            var_names[varIndex], var_val, score*100, runtime))\n",
    "        # Todo: Add expected value of ramp (sth like time from when ramp is visible\n",
    "        # Todo: until not times the rate)\n",
    "        print('Out of ... expected samples, {} were detected.'.format(len(true_inliers)))\n",
    "        vis_list.append([var_names[varIndex], var_val, score*100, runtime, true_inliers])\n",
    "    if visualize:\n",
    "        df = pd.DataFrame(vis_list)\n",
    "        tps = []\n",
    "        fps = []\n",
    "        for sample in df.iloc[:,4]:\n",
    "            tp = sum(np.array(sample) > 0.5)\n",
    "            tps.append(tp)\n",
    "            fps.append(len(sample) - tp)\n",
    "        df[5] = tps\n",
    "        df[6] = fps\n",
    "        fig = make_subplots(rows=1, cols=2, \n",
    "        subplot_titles=('TruePositives vs FalsePositives\\n(Should be high tp and low fp))', 'Runtime (lower is better)'),\n",
    "        y_title='Parameter value')\n",
    "        fig.add_trace(go.Bar(\n",
    "            y = df.iloc[:,1], x=df.iloc[:,5],\n",
    "            name=\"True positives\",\n",
    "            orientation='h', \n",
    "            textposition='inside', \n",
    "            offsetgroup=0\n",
    "        ))\n",
    "        fig.add_trace(go.Bar(\n",
    "            y = df.iloc[:,1], x=df.iloc[:,6],\n",
    "            name=\"False positives\",\n",
    "            orientation='h', \n",
    "            textposition='inside', \n",
    "            offsetgroup=0\n",
    "        ))\n",
    "        fig.add_trace(go.Bar(\n",
    "            y = df.iloc[:,1], x=df.iloc[:,3],\n",
    "            name=\"Runtime\",\n",
    "            orientation='h', \n",
    "            marker_color='orange',\n",
    "            textposition='inside'\n",
    "        ), row=1, col=2)\n",
    "        fig.update_traces(texttemplate='%{y:.3f}', insidetextanchor=\"middle\")\n",
    "        fig.update_xaxes(title_text=\"Sample count\", row=1, col=1)\n",
    "        fig.update_xaxes(title_text=\"Time [s]\", row=1, col=2)\n",
    "        fig.update_layout(title_text=\"Performance for different \" + vis_list[0][0] + \" values\")\n",
    "        fig.show()\n",
    "        return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard parameters\n",
    "params = [0.017, 0.125, 50, 0.1, 0.8, 4, 100, [0, 30, -3.5, 3.5, -1, 1.5]]\n",
    "# Change each parameter by 50 to 100% and explore their influence\n",
    "for i in range(7):\n",
    "    if i != 4:\n",
    "        dumb_optimizer2(i, params[i]*0.5, params[i]*2, 4)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "767d51c1340bd893661ea55ea3124f6de3c7a262a8b4abca0554b478b1e2ff90"
  },
  "kernelspec": {
   "display_name": "Python 2.7.17 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
