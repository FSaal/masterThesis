{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0e4e365b",
   "metadata": {},
   "source": [
    "In this notebook, different statistics of the detected ramp planes will be analyzed and visualized.<br>\n",
    "Also a score will be calculated to determine how well the algorithm works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55eeb54a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tf.transformations import euler_from_quaternion, euler_matrix\n",
    "import ros_numpy\n",
    "import pcl\n",
    "import numpy as np\n",
    "import rosbag\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.offline import plot\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.io as pio\n",
    "pio.templates.default = 'plotly_dark'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5edc5c5",
   "metadata": {},
   "source": [
    "The following values need to be adjusted for each rosbag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24718ccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ground truth coordinates of ramp (measured by using globalmap points)\n",
    "x_range = [24, 36]\n",
    "y_range = [-2.6, 1.5] \n",
    "# Kind of recording: Straight onto curved ramp\n",
    "# Rosbag path\n",
    "bag_path = '/home/user/rosbags/big/evaluation/2021-10-19-15-30-50_hdl.bag'\n",
    "\n",
    "# # Ground truth coordinates of ramp (measured by using globalmap points)\n",
    "# x_range = [20, 32]\n",
    "# y_range = [-1.4, 2.5] \n",
    "# # Kind of recording: Straight onto straight ramp\n",
    "# # Rosbag path\n",
    "# bag_path = '/home/user/rosbags/big/evaluation/2021-10-19-15-43-09_hdl.bag'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c95e6b6b",
   "metadata": {},
   "source": [
    "Load data (pointcloud and odom) from rosbag and make sure both topics are synchronized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e52f6b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load rosbag\n",
    "bag = rosbag.Bag(bag_path)\n",
    "\n",
    "# Synch help\n",
    "msg_pose_t = []\n",
    "msg_lidar_t = []\n",
    "\n",
    "# Extract data from hdl bag\n",
    "# Contains raw lidar data and the position/orientation of car\n",
    "pose = []\n",
    "for topic, msg, t in bag.read_messages(topics='/odom'):\n",
    "    msg_pose_t.append(t.to_time())\n",
    "    pose.append(msg.pose.pose)\n",
    "lidar = []\n",
    "for topic, msg, t in bag.read_messages(topics='/right/rslidar_points'):\n",
    "    msg_lidar_t.append(t.to_time())\n",
    "    lidar.append(msg)\n",
    "\n",
    "# Difference between length of the two topics\n",
    "len_diff = len(msg_lidar_t) - len(msg_pose_t)\n",
    "# Time difference at start and end of recording\n",
    "diff1 = msg_pose_t[0] - msg_lidar_t[0]\n",
    "diff2 = msg_pose_t[-1] - msg_lidar_t[-1]\n",
    "if  diff1 > 0:\n",
    "    print('Odom data is behind lidar data by {}s at the beginning and {}s at the end'.format(diff1, diff2))\n",
    "    print('Removed the {} first samples from lidar to account for this'.format(len_diff))\n",
    "    lidar = lidar[len_diff:]\n",
    "else:\n",
    "    print('Lidar data is behind odom data by {}s at the beginning and {}s at the end'.format(diff1, diff2))\n",
    "    print(msg_pose_t[abs(len_diff)] - msg_lidar_t[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3875e3c",
   "metadata": {},
   "source": [
    "Class of the actual ramp detection algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b047e72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# My ROS Node\n",
    "class VisualDetection():\n",
    "\n",
    "    def __init__(self):\n",
    "        self.calibrated = False\n",
    "        self.rp = [0, 0]\n",
    "        self.ramp_data = [[] for i in range(5)]\n",
    "        self.publish_clouds = False\n",
    "        self.arr = np.zeros((1,3))\n",
    "        # x coordinates where ramp starts\n",
    "        self.ramp_start = x_range[0]\n",
    "\n",
    "    def spin(self, cloud, pose):\n",
    "        self.cloud = cloud\n",
    "        self.pose = pose\n",
    "        # Robosense Lidar has a rate of 10 Hz\n",
    "        # Convert PointCloud2 msg to numpy array\n",
    "        pc_array = ros_numpy.point_cloud2.pointcloud2_to_xyz_array(self.cloud, remove_nans=True)\n",
    "\n",
    "        # Apply lidar to car frame transformation\n",
    "        pc_array_tf = self.transform_pc(pc_array, roll=0, pitch=19.174, yaw=0, transl_x=-1.944)\n",
    "\n",
    "        # Filter unwanted points (to reduce point cloud size) with passthrough filter\n",
    "        # TODO: Check if Points further than 30m have intensity less than 10%\n",
    "        # * Max Range of lidar is 100m (30m @ 10% NIST)\n",
    "        pc_array_cut = self.reduce_pc(pc_array_tf, 0, 30, -3.5, 3.5, -1, 1.5)\n",
    "            \n",
    "        # Convert numpy array to pcl object\n",
    "        pc_cut = pcl.PointCloud()\n",
    "        pc_cut.from_array(pc_array_cut.astype('float32'))\n",
    "\n",
    "        # Downsample point cloud using voxel filter to further decrease size\n",
    "        pc_small = self.voxel_filter(pc_cut, 0.1)\n",
    "        if self.publish_clouds: self.publish_pc(pc_small.to_list(), 'pc_small')\n",
    "\n",
    "        # Perform RANSAC until no new planes are being detected\n",
    "        plane_coor, data = self.plane_detection(pc_small, 100, 4)\n",
    "        return plane_coor, data, self.relative_to_absolute(pc_array_cut)\n",
    "        # self.ramp_detection_confidence(10, 5, data)\n",
    "\n",
    "    def transform_pc(self, pc, roll=0, pitch=0, yaw=0, transl_x=1.753, transl_y=0, transl_z=1.156):\n",
    "        \"\"\"Transformation from Lidar frame to car frame. Rotation in rad and translation in m.\"\"\"\n",
    "        # Rotation matrix\n",
    "        rot = euler_matrix(roll, pitch, yaw, 'sxyz')[:3, :3]\n",
    "        # Apply rotation\n",
    "        pc_tf = np.inner(pc, rot)\n",
    "\n",
    "        # Translation\n",
    "        translation = [transl_x, transl_y, transl_z]\n",
    "        # Combine rotation and translation\n",
    "        pc_tf += translation\n",
    "        return pc_tf\n",
    "\n",
    "    def reduce_pc(self, pc, x_lower, x_upper, y_lower, y_upper, z_lower, z_upper):\n",
    "        \"\"\"Removes points outside of box\"\"\"\n",
    "        pc_cut = pc[(pc[:, 0] > x_lower) & (pc[:, 0] < x_upper) & (pc[:, 1] > y_lower) & (\n",
    "            pc[:, 1] < y_upper) & (pc[:, 2] > z_lower) & (pc[:, 2] < z_upper)]\n",
    "        return pc_cut\n",
    "\n",
    "    def voxel_filter(self, pc, leaf_size):\n",
    "        \"\"\"Downsample point cloud using voxel filter\"\"\"\n",
    "        vg = pc.make_voxel_grid_filter()\n",
    "        # Leaf_size is the length of the side of the voxel cube in m\n",
    "        vg.set_leaf_size(leaf_size, leaf_size, leaf_size)\n",
    "        pc_filtered = vg.filter()\n",
    "        # print('Reduced size from {} to {}'.format(pc.size, pc_filtered.size))\n",
    "        return pc_filtered\n",
    "\n",
    "    def plane_detection(self, pc, min_points, max_planes):\n",
    "        \"\"\"Detects all planes in point cloud\"\"\"\n",
    "        # Ground vector\n",
    "        g_vec = None\n",
    "        counter = 0\n",
    "        while pc.size > min_points and counter < max_planes:\n",
    "            # Detect most dominate plane and get inliers and normal vector\n",
    "            indices, coefficients = self.ransac(pc)\n",
    "            n_vec = coefficients[:-1]\n",
    "\n",
    "            # Split pointcloud in inliers and outliers of plane\n",
    "            pc, plane, pc_points = self.split_pc(pc, indices)\n",
    "\n",
    "            # Exit if plane is empty\n",
    "            if not plane:\n",
    "                print('ERROR: No plane could be detected')\n",
    "                return [], []\n",
    "\n",
    "            # Ignore walls to the side or in front\n",
    "            if self.is_plane_near_ground(n_vec):\n",
    "                # First ground like detection is most probably the ground\n",
    "                if g_vec is None:\n",
    "                    g_vec = n_vec\n",
    "                    if self.publish_clouds: self.publish_pc(plane, 'pc_ground')\n",
    "                # Either ground is detected again or potential ramp\n",
    "                else:\n",
    "                    # self.pub_angle.publish(angle)\n",
    "                    is_ramp, data = self.ramp_detection(plane, g_vec, n_vec, 4, 7, 2, 4)\n",
    "                    if is_ramp:\n",
    "                        # Transform plane from local rslidar coordinates to global map coordinates\n",
    "                        plane_global = self.relative_to_absolute(plane)\n",
    "                    \n",
    "                        if self.publish_clouds: self.publish_pc(plane, 'pc_ramp')\n",
    "                        return plane_global, data\n",
    "                    else:  \n",
    "                        continue\n",
    "            counter += 1\n",
    "        return [], []\n",
    "\n",
    "    def relative_to_absolute(self, pc):\n",
    "        \"\"\"Transforms relative lidar data to absolute by adding translation rotating\"\"\"\n",
    "        # pc_arr = pc.to_array()\n",
    "        pc_arr = np.array(pc)\n",
    "    \n",
    "        # Odometer\n",
    "        pos = self.pose.position\n",
    "        translation = [pos.x, pos.y, pos.z]\n",
    "        ori = self.pose.orientation\n",
    "        quat = [ori.x, ori.y, ori.z, ori.w]\n",
    "        roll, pitch, yaw = euler_from_quaternion(quat)\n",
    "\n",
    "        # Rotation matrix\n",
    "        rot = euler_matrix(roll, pitch, yaw, 'sxyz')[:3, :3]\n",
    "        # Apply rotation\n",
    "        pc_tf = np.inner(pc_arr, rot)\n",
    "\n",
    "        # Combine rotation and translation\n",
    "        pc_tf += translation\n",
    "        return pc_tf\n",
    "\n",
    "    def ramp_detection(\n",
    "            self, plane, g_vec, n_vec, min_angle, max_angle, \n",
    "            min_width, max_width, logging=False):\n",
    "        \"\"\"Checks if conditions to be considered a ramp are fullfilled.\"\"\"\n",
    "        # Convert pcl plane to numpy array\n",
    "        plane_array = np.array(plane)\n",
    "\n",
    "        # Calculate angle [deg] between new and previously recorded normal vector of ground\n",
    "        angle = self.angle_calc(g_vec, n_vec)\n",
    "        # Assert ramp angle threshold\n",
    "        if min_angle <= angle <= max_angle:\n",
    "            if logging: print('ANGLE PASSED')\n",
    "            pass\n",
    "        else:\n",
    "            if logging: print('Angle wrong with {}'.format(angle))\n",
    "            return False, []\n",
    "\n",
    "        # Get ramp width (Difference between y-values)\n",
    "        width = max(plane_array[:, 1]) - min(plane_array[:, 1])\n",
    "        # Assert ramp width threshold\n",
    "        if min_width <= width <= max_width:\n",
    "            if logging: print('WIDTH PASSED')\n",
    "            pass\n",
    "        else:\n",
    "            if logging: print('Width wrong with {}'.format(width))\n",
    "            return False, []\n",
    "\n",
    "        # Ramp distance (x-value of nearest point of the plane)\n",
    "        dist = min(plane_array[:,0])\n",
    "\n",
    "        self.angle = angle\n",
    "        self.d = dist\n",
    "        if logging:\n",
    "            print('Possible ramp in {:05.2f}m with angle {:05.2f}deg and width {:05.2f}m'.format(\n",
    "            dist, angle, width))        \n",
    "        true_dist = self.ramp_start - self.pose.position.x\n",
    "        return True, [angle, width, dist, true_dist]\n",
    "\n",
    "    def ransac(self, pc):\n",
    "        \"\"\"Finds inliers and normal vector of dominant plane\"\"\"\n",
    "        # 50?\n",
    "        seg = pc.make_segmenter_normals(50)\n",
    "        # Doubles the speed if True\n",
    "        seg.set_optimize_coefficients(True)\n",
    "        seg.set_model_type(pcl.SACMODEL_NORMAL_PLANE)\n",
    "        seg.set_method_type(pcl.SAC_RANSAC)\n",
    "        # How close a point must be to model to be considered inlier\n",
    "        seg.set_distance_threshold(0.01)\n",
    "        # normal_distance_weight?\n",
    "        seg.set_normal_distance_weight(0.01)\n",
    "        # How many tries\n",
    "        seg.set_max_iterations(100)\n",
    "        indices, coefficients = seg.segment()\n",
    "        return indices, coefficients\n",
    "\n",
    "    def split_pc(self, pc, inliers):\n",
    "        \"\"\"Extract detected plane from point cloud and split into two pcs\"\"\"\n",
    "        # Get point cooridnates of plane\n",
    "        detected_plane = [pc[i] for i in inliers]\n",
    "        # Point cloud of detected plane (inliers)\n",
    "        pc_inliers = pc.extract(inliers)\n",
    "\n",
    "        # Point cloud of outliers\n",
    "        outlier_indices = list(set(np.arange(pc.size)).symmetric_difference(inliers))\n",
    "        pc_outliers = pc.extract(outlier_indices)\n",
    "\n",
    "        return pc_outliers, detected_plane, pc_inliers\n",
    "\n",
    "    def is_plane_near_ground(self, v, threshold=0.8):\n",
    "        \"\"\"Returns True if plane is on the ground (and false if e.g. side wall)\"\"\"\n",
    "        return abs(v[2]) > threshold   \n",
    "\n",
    "    def angle_calc(self, v1, v2, degrees=True):\n",
    "        \"\"\"Calculate angle between two vectors (planes)\"\"\"\n",
    "        # Assuming both vectors can be rotated alongside one axis to be aligned\n",
    "        dot = np.dot(v1, v2)\n",
    "        if dot <= 1:\n",
    "            angle = np.arccos(dot)\n",
    "        else:\n",
    "            # print('ERROR: dot product > 1')\n",
    "            # print('v1 is {} abs({}) and v2 is {} abs ({})'.format(v1, np.linalg.norm(v1), v2, np.linalg.norm(v2)))\n",
    "            angle = 0\n",
    "\n",
    "        if degrees is True:\n",
    "            return np.degrees(angle)\n",
    "        else:\n",
    "            return angle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51a68a52",
   "metadata": {},
   "source": [
    "Run algorithm with rosbag data.<br>\n",
    "Store many different calculated metrics generated by the algorithm in a pandas data frame (to allow a faster plotting)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "089adf81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create instance of class (using standard parameters):\n",
    "vd = VisualDetection()\n",
    "# Lists to fill, will contain entry for each plane\n",
    "planes = []\n",
    "ramp_stats = []\n",
    "true_dist = []\n",
    "all_points = []\n",
    "for i in range(len(lidar)):\n",
    "    plane_points, data, pc_whole = vd.spin(lidar[i], pose[i])\n",
    "    planes.append(plane_points)\n",
    "    ramp_stats.append(data)\n",
    "    all_points.append(pc_whole)\n",
    "    # True distance to start of ramp\n",
    "    true_dist.append(x_range[0] - pose[i].position.x)\n",
    "true_dist = np.array(true_dist)\n",
    "\n",
    "# Remove empty lists (when no ramp has been detected)\n",
    "# because information such as angle, width of ramp etc \n",
    "# are only stored when a ramp is detected, 0 otherwise\n",
    "ramp_arrays = [x for x in planes if not isinstance(x, list)]\n",
    "ramp_stats = [x for x in ramp_stats if x != []]\n",
    "# Get indices where ramp has been detected\n",
    "ramp_indices = [i for i,v in enumerate(planes) if not isinstance(v, list)]\n",
    "\n",
    "# Convert list to dictionary\n",
    "dic = []\n",
    "for i, arr in enumerate(ramp_arrays):\n",
    "    for j, point in enumerate(arr):\n",
    "        dic.append(\n",
    "            {\n",
    "                'sampleIdx': i,\n",
    "                'pointIdx': j,\n",
    "                'x': point[0],\n",
    "                'y': point[1],\n",
    "                'z': point[2]\n",
    "            }\n",
    "        )\n",
    "# And finally to pandas data frame\n",
    "df = pd.DataFrame(dic)\n",
    "# Reorder columns\n",
    "df = df[['sampleIdx', 'pointIdx', 'x', 'y', 'z']]\n",
    "\n",
    "# Add some buffer to the true ramp region (for tidy plots)\n",
    "def add_buffer(range, margin=3):\n",
    "    for i,v in enumerate(range):\n",
    "        if i == 0:\n",
    "            low = int(round(v)) - margin\n",
    "        else:\n",
    "            high = int(round(v)) + margin\n",
    "    return [low, high]\n",
    "x_fixed = add_buffer(x_range)\n",
    "y_fixed = add_buffer(y_range)\n",
    "\n",
    "# Check if a point lies within ramp region\n",
    "lies_inside = []\n",
    "for i,x in enumerate(df['x']):\n",
    "    if x_range[0] < x < x_range[1]:\n",
    "        if y_range[0] < df['y'][i] < y_range[1]:\n",
    "            # True if x and y coordinate inside region\n",
    "            lies_inside.append(True)\n",
    "        else:\n",
    "            lies_inside.append(False)\n",
    "    else:\n",
    "        lies_inside.append(False)\n",
    "# Add column (bool: if point lies in region) to data frame\n",
    "df['inlier'] = lies_inside\n",
    "\n",
    "# Calculate how many points of each sample lie in ramp region\n",
    "true_inliers = []\n",
    "samples_num = df.sampleIdx.max() + 1\n",
    "for i in range(samples_num):\n",
    "    # Bool list of inliers and outliers of sample\n",
    "    bool_lst = df[df['sampleIdx'] == i]['inlier']\n",
    "    # Percentage of inliers of sample\n",
    "    true_inliers.append(sum(bool_lst) / float(len(bool_lst)))\n",
    "\n",
    "# New dataframe with stats for each frame\n",
    "# Structure reminder of ramp_stats: [angle, width, dist, true_dist]\n",
    "dic = []\n",
    "for i in range(samples_num):\n",
    "    dic.append(\n",
    "        {\n",
    "            'sampleIdx': i,\n",
    "            'TrueInliers': true_inliers[i],\n",
    "            'Angle': ramp_stats[i][0],\n",
    "            'Width': ramp_stats[i][1],\n",
    "            'Dist': ramp_stats[i][2],\n",
    "            'TrueDist': ramp_stats[i][3],\n",
    "        }\n",
    "    )\n",
    "# Convert dictionary to dataframe\n",
    "df_stats = pd.DataFrame(dic)\n",
    "# Reorder columns\n",
    "df_stats = df_stats[['sampleIdx', 'TrueInliers', 'Angle', 'Width', 'Dist', 'TrueDist']]\n",
    "\n",
    "# Filter the best detections\n",
    "df_stats_good = df_stats[df_stats['TrueInliers'] > 0.7]\n",
    "# Filter the bad detections\n",
    "df_stats_bad = df_stats[df_stats['TrueInliers'] < 0.3]\n",
    "# Filter the average detections\n",
    "df_stats_avg = df_stats[0.3 < df_stats['TrueInliers']]\n",
    "df_stats_avg = df_stats_avg[df_stats_avg['TrueInliers'] < 0.7]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5bfb85e",
   "metadata": {},
   "source": [
    "## Score calculation\n",
    "To calculate the score, a range has to be specified in which the lidar should be able to detect the ramp. Looking at the histogram, the range between 4 and 10 m before the ramp seems reasonable.\n",
    "\n",
    "Now filter all the data, such that only samples in the range of 4 to 10 m before the ramp are used.\n",
    "\n",
    "## Other todo stuff:\n",
    "- Analyze why some samples where not detected as ramp (especially in the 4-9m range)\n",
    "- Combine multiple datasets (probably only the straight and slightly skewed recordings) and calculate scores (remove all \"advanced plots\", focus on the score)\n",
    "- Perform grid search when fused dataset is finished\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e2c88a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_score(min_dist, max_dist):\n",
    "    # Sensitivity\n",
    "    # How many sample were recorded in given range\n",
    "    expected_detections = len(true_dist[(min_dist < true_dist) & (true_dist < max_dist)])\n",
    "    # How many samples were identified as ramp in given range\n",
    "    actual_detections = len(df_stats['TrueDist'][(min_dist < df_stats['TrueDist']) & (df_stats['TrueDist'] < max_dist)])\n",
    "    # Calculate ratio\n",
    "    sensitivity = float(actual_detections) / expected_detections\n",
    "    print('Out of {} recorded samples {} were detected in the range of {} to {}m before the ramp.'.format(\n",
    "        expected_detections, actual_detections, min_dist, max_dist))\n",
    "    print('Resulting in a score of {:.2f}%\\n'.format(sensitivity*100))\n",
    "\n",
    "    # Inlier score \n",
    "    f = df_stats['TrueInliers'][(min_dist < df_stats['TrueDist']) & (df_stats['TrueDist'] < max_dist)]\n",
    "    score2 = sum(f) / len(f)\n",
    "    print('Of the {} detected planes {:.2f}% inlier points were actually inside the ramp region.\\n'.format(\n",
    "        actual_detections, score2*100))\n",
    "\n",
    "    # False positives?  \n",
    "    f = df_stats['TrueInliers'][(min_dist < df_stats['TrueDist']) & (df_stats['TrueDist'] < max_dist)]\n",
    "    thresh = 0.5\n",
    "    true_detections = sum(f > thresh)\n",
    "    score3 = float(true_detections) / len(f)\n",
    "    print('Of the {} detected planes {} had at least {}% of points inside the ramp region.'.format(\n",
    "        actual_detections, true_detections, int(thresh*100)))\n",
    "    print('Resulting in a score of {:.2f}%\\n\\n'.format(score3*100))\n",
    "\n",
    "calc_score(4, 10)\n",
    "calc_score(0, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3c2d146",
   "metadata": {},
   "source": [
    "# Plots"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "527ff8e3",
   "metadata": {},
   "source": [
    "**How was this plot created:**\n",
    "- Calculate distance to start of ramp using odometry data from hdl_slam \n",
    "- Calculate how many lidar samples were recorded during a 1m drive (e.g. car took 0.5s for 1m $\\rightarrow$ lidar took 5 samples (because $f_\\text{Lidar}=$ 10Hz))\n",
    "- Calculate how many samples of them were actually identified as a ramp by the algorithm\n",
    "- Represent both values in a bar plot\n",
    "- Value at bar represents the lower range (e.g. bar at 15 means 16m to 15m)\n",
    "\n",
    "**What to take from this plot:**<br>\n",
    "- At which distance to the ramp is the lidar most reliable?<br>\n",
    "- $\\rightarrow$ Range between 10m to 4m seems to be the most reliable\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c611aa1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "expected_detections = []\n",
    "actual_detections = []\n",
    "# Split dataset in 1m intervals\n",
    "for i in range(15, -5, -1):\n",
    "    # Filter distance to ramp (from odom data) in 1m intervals\n",
    "    expected_detections.append(len(true_dist[(i < true_dist) & (true_dist < i + 1)]))\n",
    "    # Get corresponding distance estimations\n",
    "    actual_detections.append(len(df_stats['TrueDist'][(i < df_stats['TrueDist']) & (df_stats['TrueDist'] < i + 1)]))\n",
    "# Create pandas data frame\n",
    "eval_df = pd.DataFrame()\n",
    "# Distance to ramp e.g. a value of 15 means interval from 16m to 15m \n",
    "eval_df['distToRamp'] = range(15, -5, -1)\n",
    "eval_df['expectedDetections'] = expected_detections\n",
    "eval_df['actualDetections'] = actual_detections\n",
    "\n",
    "# Plot\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Bar(\n",
    "    y = eval_df['expectedDetections'], x=eval_df['distToRamp'],\n",
    "    name=\"False negatives (Not detected)\",\n",
    "    offsetgroup=0\n",
    "))\n",
    "fig.add_trace(go.Bar(\n",
    "    y = eval_df['actualDetections'], x=eval_df['distToRamp'],\n",
    "    name=\"True positives (Detected)\",\n",
    "    offsetgroup=0\n",
    "))\n",
    "fig.update_xaxes(title_text=\"Distance to ramp [m]\", autorange='reversed')\n",
    "fig.update_yaxes(title_text=\"Number of ramps detected\")\n",
    "fig.update_layout(title_text=\"How many samples were collected in 1m intervals and how many of them have been identified as ramp\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32d7b341",
   "metadata": {},
   "source": [
    "**How was this plot created:**\n",
    "- Every time a ramp is detected certain metrics such as angle, width, distance are estimated by the algorithm\n",
    "- Compare predictions to the true values, true values were measured by hand\n",
    "- Calculate some stats like standard deviation or average error and add them\n",
    "- Represent values as a line plot\n",
    "\n",
    "**What to take from this plot:**\n",
    "- (Lars wanted it)\n",
    "- Distance to ramp:\n",
    "    - Distance is estimated quite well up to about 3m before the ramp\n",
    "    - There does seem to be a slight offset (manual measurement might have been wrong)\n",
    "- Angle:\n",
    "    - Quite a bit of variance at far and close distance, but very small deviation in the range 9m to 3m\n",
    "    - Because ramp does not have a constant angle, angle estimation of 4° etc. at the beginning of the ramp might be correct \n",
    "- Width:\n",
    "    - Mhm...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b170202b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distance estimation evaluation\n",
    "diff = df_stats['Dist'] - df_stats['TrueDist']\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=df_stats['TrueDist'], y=df_stats['TrueDist'], name='Measured (hdl)'))\n",
    "fig.add_trace(go.Scatter(x=df_stats['TrueDist'], y=df_stats['Dist'], name='Estimated'))\n",
    "fig.update_traces(mode='lines+markers')\n",
    "fig.update_layout(title='Difference between estimated and actual distance to ramp')\n",
    "fig.add_annotation(text=\"Standard deviation: {:.2f}m<br>Average error: {:.2f}m<br>Median error: {:.2f}m\".\n",
    "                format(np.std(diff), np.mean(diff), np.median(diff)),\n",
    "                  xref=\"paper\", yref=\"paper\", x=1, y=1, showarrow=False)\n",
    "fig.update_xaxes(title_text='(actual) Distance [m]', autorange='reversed')\n",
    "fig.update_yaxes(title_text='Distance [m]')\n",
    "fig.show()\n",
    "\n",
    "# Angle estimation evaluation\n",
    "true_angle = 6\n",
    "diff = df_stats['Angle'] - true_angle\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=df_stats['TrueDist'], y=true_angle*np.ones(len(df_stats)), \n",
    "                        name='Measured', mode='lines'))\n",
    "fig.add_trace(go.Scatter(x=df_stats['TrueDist'], y=df_stats['Angle'],\n",
    "                        name='Estimated', mode='lines+markers'))\n",
    "fig.update_layout(title='Difference between estimated and actual angle of ramp')\n",
    "fig.add_annotation(text=\"Average: {:.2f}<br>Standard deviation: {:.2f}°<br>Average error: {:.2f}°<br>Median error: {:.2f}°\".\n",
    "                format(np.mean(df_stats['Angle']), np.std(diff), np.mean(diff), np.median(diff)),\n",
    "                  xref=\"paper\", yref=\"paper\", x=1, y=1, showarrow=False)\n",
    "fig.update_xaxes(title_text='Distance to ramp [m]', autorange='reversed')\n",
    "fig.update_yaxes(title_text='Ramp angle [°]')\n",
    "fig.show()\n",
    "\n",
    "# Width estimation evaluation\n",
    "# Whole width (including curb)\n",
    "true_width = y_range[-1] - y_range[0]\n",
    "# Only street (measured by hand)\n",
    "true_width_drive = 2.9\n",
    "diff = df_stats['Width'] - true_width\n",
    "diff_drive = df_stats['Width'] - true_width_drive\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=df_stats['TrueDist'], y=true_width*np.ones(len(df_stats)),\n",
    "                        name='Measured (whole)', mode='lines'))\n",
    "fig.add_trace(go.Scatter(x=df_stats['TrueDist'], y=true_width_drive*np.ones(len(df_stats)),\n",
    "                        name='Measured (drivable)', mode='lines'))\n",
    "fig.add_trace(go.Scatter(x=df_stats['TrueDist'], y=df_stats['Width'],\n",
    "                        name='Estimated', mode='lines+markers'))\n",
    "fig.update_layout(title='Difference between estimated and actual width of ramp')\n",
    "fig.add_annotation(text=\"Average: {:.2f}<br>Standard deviation: {:.2f}m<br>Average error: {:.2f}m<br>Median error: {:.2f}m\".\n",
    "                format(np.mean(df_stats['Width']), np.std(diff), np.mean(diff), np.median(diff)),\n",
    "                  xref=\"paper\", yref=\"paper\", x=1, y=1, showarrow=False)\n",
    "fig.add_annotation(text=\"Standard deviation: {:.2f}m<br>Average error: {:.2f}m<br>Median error: {:.2f}m\".\n",
    "                format(np.std(diff_drive), np.mean(diff_drive), np.median(diff_drive)),\n",
    "                  xref=\"paper\", yref=\"paper\", x=1, y=0, showarrow=False)\n",
    "fig.update_xaxes(title_text='Distance to ramp [m]', autorange='reversed')\n",
    "fig.update_yaxes(title_text='Ramp width [m]')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb13e823",
   "metadata": {},
   "source": [
    "**How was this plot created:**\n",
    "- Every time the algorithm detects a ramp, the coordinates of the inliers are stored\n",
    "- But often times not all points in ramp region are detected\n",
    "- Display points detected by algorithm in one color and all the other points recorded by the lidar in another color\n",
    "- Add an area of the true ramp region (measured by hand)\n",
    "- Calculate percentage of inliers how lie in ramp region\n",
    "- Do this for every sample which was detected as ramp \n",
    "- Add a slider (just to show off)\n",
    "\n",
    "**What to take from this plot:**\n",
    "- (Plotly is cool)\n",
    "- Only very few \"lines\" are thrown on the ground / on to the ramp\n",
    "- Distances of over 2m between two lines are common (especially at higher distances)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "670ee444",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "trace_list1 = []\n",
    "trace_list2 = []\n",
    "# Add traces, one for each slider step\n",
    "for step in range(df['sampleIdx'].max() + 1):\n",
    "    trace_list1.append(\n",
    "        go.Scatter(\n",
    "            visible=False, mode='markers',\n",
    "            x=df[df['sampleIdx'] == step]['x'],\n",
    "            y=df[df['sampleIdx'] == step]['y'], name='Detected by algorithm as ramp'\n",
    "            ))\n",
    "    trace_list2.append(\n",
    "        go.Scatter(\n",
    "            visible=False, mode='markers',\n",
    "            marker=dict(opacity=0.5),\n",
    "            x=all_points[ramp_indices[step]][:,0],\n",
    "            y=all_points[ramp_indices[step]][:,1], name='All lidar points'\n",
    "            ))\n",
    "fig = go.Figure(data=trace_list2 + trace_list1)\n",
    "fig.data[0].visible = True\n",
    "fig.add_shape(type='rect', x0=x_range[0], x1=x_range[1], \n",
    "              y0=y_range[0], y1=y_range[1], fillcolor='red', opacity=0.2)\n",
    "# Set static axes limits\n",
    "fig.update_xaxes(range = x_fixed)\n",
    "fig.update_yaxes(range = y_fixed)\n",
    "\n",
    "# Create and add slider\n",
    "steps = []\n",
    "for i in range(len(fig.data)/2):\n",
    "    step = dict(\n",
    "        method=\"update\",\n",
    "        args=[{\"visible\": [False] * len(fig.data)},\n",
    "              {\"title\": '{:.2f}% of detected points lie in the ramp region. Was detected {:.2f}m infront of ramp'.format(\n",
    "                  true_inliers[i]*100, df_stats.iloc[i,-1])}],  # layout attribute\n",
    "    )\n",
    "    step[\"args\"][0][\"visible\"][i] = True  # Toggle i'th trace to \"visible\"\n",
    "    step[\"args\"][0][\"visible\"][i+len(fig.data)/2] = True  # Toggle i'th trace to \"visible\"\n",
    "    steps.append(step)\n",
    "sliders = [dict(\n",
    "    active=0,\n",
    "    currentvalue={\"prefix\": \"Deteced plane: \"},\n",
    "    steps=steps)]\n",
    "fig.update_layout(sliders=sliders, xaxis_title='Global x coor [m]', \n",
    "    yaxis_title='Global y coor [x]', showlegend=True)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad25f1de",
   "metadata": {},
   "source": [
    "**How was this plot created:**\n",
    "- Similar to previous plot\n",
    "- For every recorded lidar sample all points are displayed\n",
    "- Add an area of the true ramp region (measured by hand)\n",
    "\n",
    "**What to take from this plot:**\n",
    "- Just gives an idea of what the lidar sees, might be useful to optimize mount pitch angle\n",
    "- Also might give information, about why some samples are not recognized as ramp, eventhough they should be"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e753aee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "# Add traces, one for each slider step\n",
    "for step in range(len(all_points)):\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            visible=False, mode='markers',\n",
    "            x=all_points[step][:,0],\n",
    "            y=all_points[step][:,1], name='All lidar points'\n",
    "            ))\n",
    "fig.data[0].visible = True\n",
    "fig.add_shape(type='rect', x0=x_range[0], x1=x_range[1], \n",
    "              y0=y_range[0], y1=y_range[1], fillcolor='red', opacity=0.2)\n",
    "# Set static axes limits\n",
    "fig.update_xaxes(range = x_fixed)\n",
    "fig.update_yaxes(range = y_fixed)\n",
    "\n",
    "# Create and add slider\n",
    "steps = []\n",
    "for i in range(len(fig.data)):\n",
    "    ramp_det = 'A' if i in ramp_indices else 'No'\n",
    "    step = dict(\n",
    "        method=\"update\",\n",
    "        args=[{\"visible\": [False] * len(fig.data)},\n",
    "              {\"title\": '{:.2f}m infront of ramp. {} ramp has been detected'.format(\n",
    "                #   true_inliers[i]*100, df_stats.iloc[i,-1])}],  # layout attribute\n",
    "                  true_dist[i], ramp_det)}],  # layout attribute\n",
    "\n",
    "    )\n",
    "    step[\"args\"][0][\"visible\"][i] = True  # Toggle i'th trace to \"visible\"\n",
    "    steps.append(step)\n",
    "sliders = [dict(\n",
    "    active=0,\n",
    "    currentvalue={\"prefix\": \"Deteced plane: \"},\n",
    "    steps=steps)]\n",
    "fig.update_layout(sliders=sliders, xaxis_title='Global x coor [m]', \n",
    "    yaxis_title='Global y coor [x]', showlegend=True)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3ff5e9b",
   "metadata": {},
   "source": [
    "**How was this plot created:**\n",
    "- Every time the algorithm detects a ramp, the coordinates of the inlier points are saved\n",
    "- Put all point coordinates of every detection together\n",
    "- Add an area of the true ramp region (measured by hand)\n",
    "- Display as a scatter plot and also as a heatmap\n",
    "\n",
    "**What to take from this plot:**\n",
    "- Shows which points are most commonly detected \n",
    "- Majority of points are inside ramp region\n",
    "- ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22b2e970",
   "metadata": {},
   "outputs": [],
   "source": [
    "# All points#\n",
    "fig = px.scatter(x = df['x'], y = df['y'], \n",
    "                title=\"Coordinates of all points\")\n",
    "fig.add_shape(type='rect', x0=x_range[0], x1=x_range[1], \n",
    "              y0=y_range[0], y1=y_range[1], fillcolor='red', opacity=0.2)\n",
    "fig.show()\n",
    "\n",
    "fig = px.density_heatmap(df, x='x', y='y', nbinsx=200, nbinsy=50, \n",
    "                        title=\"Heatmap, where do the most points get detected?\")\n",
    "fig.add_shape(type='rect', x0=x_range[0], x1=x_range[1],\n",
    "              y0=y_range[0], y1=y_range[1], line=dict(color=\"White\", width=3), opacity=0.9)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09540088",
   "metadata": {},
   "source": [
    "**How was this plot created:**\n",
    "- Every time a ramp is detected certain metrics such as angle, width, distance are estimated by the algorithm\n",
    "- Because the inliers of a detected ramp do not always lie in the ramp region, split the dataset in \"good\" and \"bad\" sets\n",
    "- \"good\" sets are samples, where more than 70% of inliers lie in the ramp region, whereas less than 30% do so in a \"bad\" sample\n",
    "- For each set display the metrics as a histogram\n",
    "\n",
    "**What to take from this plot:**\n",
    "- Helps to selected a good metric, which can be used as an constraint in the detection\n",
    "- Look for metrics with a low variance in the \"good\" dataset $\\rightarrow$ potentially good metric\n",
    "- Look for metrics with a high variance in the \"good\" dataset $\\rightarrow$ potentially bad metric\n",
    "- Look for metrics with a lwo variance in the \"bad\" dataset $\\rightarrow$ could be used as an inverted condition\n",
    "- Angle and width seem to be fairly good metrics (condition ranges of both metrics were already reduced, was more obvious before)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcd5a622",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stats for good detection\n",
    "fig = make_subplots(rows=2, cols=2)\n",
    "fig.add_trace(go.Histogram(x=df_stats_good['Angle'], nbinsx=10, name='Angle'), row=1, col=1)\n",
    "fig.add_trace(go.Histogram(x=df_stats_good['Dist'], nbinsx=10, name='Distance'), row=1, col=2)\n",
    "fig.add_trace(go.Histogram(x=df_stats_good['Width'], nbinsx=10, name='Width'), row=2, col=1)\n",
    "fig.add_trace(go.Histogram(x=df_stats_good['TrueInliers'], nbinsx=20, name='True Inliers'), row=2, col=2)\n",
    "fig.update_layout(title='Couple of stats of well detected ramp planes, which lie > 70% in the desired area')\n",
    "fig.show()\n",
    "\n",
    "# Stats for bad detection\n",
    "fig = make_subplots(rows=2, cols=2)\n",
    "fig.add_trace(go.Histogram(x=df_stats_bad['Angle'], nbinsx=10, name='Angle'), row=1, col=1)\n",
    "fig.add_trace(go.Histogram(x=df_stats_bad['Dist'], nbinsx=10, name='Distance'), row=1, col=2)\n",
    "fig.add_trace(go.Histogram(x=df_stats_bad['Width'], nbinsx=10, name='Width'), row=2, col=1)\n",
    "fig.add_trace(go.Histogram(x=df_stats_bad['TrueInliers'], nbinsx=20, name='True Inliers'), row=2, col=2)\n",
    "fig.update_layout(title='Couple of stats of badly detected ramp planes, which lie < 30% in the desired area')\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1f7ea0bc50929e9761c6dc908034703a32cbda6ecac539c3027db206c2668001"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
