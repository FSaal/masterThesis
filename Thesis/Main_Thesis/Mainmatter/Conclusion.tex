\chapter{Discussion}
\label{ch:Conclusion}
% Do not write long version of imu or lidar acronym again
\glslocalunset{avp}
\glslocalunset{coco}
\glslocalunset{map}
\glslocalunset{imu}
\glslocalunset{lidar}
\glslocalunset{ransac}
\glslocalunset{rcnn}

\section{Summary and Conclusion}
\gls{avp} is a promising application of autonomous driving, in which the car is left in a drop-off zone and drives to its assigned parking spot on its own.
Its use in parking garages is challenging due to the tight turns and limited space.
Ramps are especially difficult to navigate on.
In this thesis different sensors and methods for the detection and classification of ramps in parking garages were developed and evaluated.

Using an \gls{imu}, a ramp could be detected by measuring the tilt of the car.
Different online methods were evaluated, the best results were achieved using a complementary filter, which fuses the accelerometer data and gyroscope data of the \gls{imu}.
By also using the data from the wheel speed sensors, an accurate estimation of the length of the ramp was possible, in addition to the average angle estimation of the ramp.
But overall it can be said that the \gls{imu} data were not very reliable.
The accelerometer data were heavily disturbed when the car did accelerate and the gyroscope data did drift significantly in some cases.

To be able to detect a ramp before entering it, different sensors were used.
At first a \gls{lidar} was tested.
Using the point cloud generated by the \gls{lidar} the planar ramp region could be extracted using the \gls{ransac} algorithm.
The length and width of the ramp could be measured, as well as the average angle of the ramp and the distance of the car to the ramp.
The ramp was successively detected in more than 95\% of the cases, if the distance to the ramp was less than \SI{25}{\metre}.
The \gls{lidar} proofed to be a reliable sensor, but the quality of the results is dependent on the resolution of the \gls{lidar} and the position where it is mounted on the car.
For both the \gls{imu} and \gls{lidar} a novel calibration method was implemented, which automatically transforms the sensor measurements into the coordinate system of the car.

Lastly, a camera was used to detect the ramp.
The object detection was done using the deep learning Mask \gls{rcnn}, which generates a segmentation mask of the object.
An own dataset was created for the training.
Due to the small size, augmented images were added to the dataset and an on the \gls{coco} dataset pretrained network was used.
The network proofed to be able to detect ramps well and achieved great results with an \gls{map} score of over 90\%.
But no quantitative description of the ramp properties was possible using this method.

Lastly the predicted segmentation mask was elevated into 3D space, by projection a 3D point cloud onto an image, removing points outside the mask, and then transforming them back into 3D space.
This was done for the point cloud generated by a stereo camera, and the point cloud of the \gls{lidar}.
This allowed for the accurate detection of the drivable part of the ramp in 3D space, whereas the \gls{lidar} algorithm did not make a distinction between the drivable part and the curb sides.
Also, the ramp properties could now be calculated.
The point cloud of the stereo camera was not as precise as the of the \gls{lidar}, but was easier to project, since no transformation between the camera image and point cloud reference frame system was needed.

Overall it can be said, that using the neural network to detect the ramp in the image and extracting the corresponding points from the \gls{lidar} point cloud, seems to be a very promising method.
The \gls{imu} data are not very reliable, but could be used to further improve the estimation from the other methods.



\section{Future Work}
In this thesis different sensors were used to detect a ramp and measure its properties.
While relatively good results could be achieved, each method could be improved further.
For the \gls{imu} other algorithms such as a Kalman filter could be tested.
Furthermore, the problem of the delay between the wheel speed sensor and \gls{imu} measurements could be investigated.
The same goes for the \gls{lidar}, other algorithms than \gls{ransac} could be tested.
There exist newer algorithms which are more efficient, which means that the downsampling and passthrough filtering could be reduced.
The neural network for the object detection could also be made more robust by using more data, preferably of other environments, in the training.

To further improve the results, the different methods could also be combined.
In this thesis the online implementation of the objection detection was not carried out, this could be done in the future.
Then, the \gls{lidar} point cloud extraction using the instance segmentation prediction could also be properly evaluated.
Another option of sensor fusion would be to use the estimated ramp properties using the \gls{lidar} data and correct them after driving on the ramp using the \gls{imu} data.
Also, the distance tracking to the ramp using the \gls{lidar} could be improved, by fusing the estimation from the \gls{lidar} data with the wheel speed measurements.

For the evaluation of the different methods the \gls{lidar} data was used, which is subject to error.
Additionally, the testing in a more controlled environment would be useful.
This could be done in a simulated environment, e.g. in \texttt{CARLA}~\footnote{\url{https://github.com/carla-simulator/carla}}~\cite{Dosovitskiy2017}.
Furthermore, testing the system in other environments could be useful.

Another potential future task would be to use the implemented methods to create a meta map of the environment.
If a map is created, e.g. using the \gls{lidar} and the \texttt{hdl\_slam} library, the location of the ramp could be labeled in the map, together with the properties of the ramp.




