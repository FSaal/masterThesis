\chapter{Experimental Setup}
\label{ch:ExperimentalSetup}

\section{Sensors}
\subsection{\glsentrytext{imu}}
\begin{figure}[htb]
	\centering
	\begin{subfigure}[b]{0.4\textwidth}
		\centering
		\includegraphics[width=\textwidth]{myAHRS.png}
		\caption{Withrobot myAHRS+ \cite{Withrobot2017}}
		\label{fig:imu_myahrs}
	\end{subfigure}
	% \hfill
	\begin{subfigure}[b]{0.4\textwidth}
		\centering
		\includegraphics[width=\textwidth]{zed2i.jpg}
		\caption{Stereolabs ZED 2i camera with integrated \acrshort{imu} \cite{Stereolabs2019}}
		\label{fig:imu_zed}
	\end{subfigure}
	\caption{The two used \acrshort{imu}s during the experiments}
	\label{fig:imus_used}
\end{figure}
Two different \glspl{imu} will be used for the experiment.\\
The first one being the Withrobot myAHRS+, a low-cost high performance \gls{ahrs}.
An \gls{ahrs} contains an \gls{imu} and outputs the raw measurements of the sensors, but also has an on-board processing system which estimates attitude and heading.
The myAHRS+ uses an extended Kalman filter for the estimation and outputs the estimation in quaternion form and also in Euler angles.\\
The second \gls{imu} used during the experiment is integrated in the Stereolabs ZED 2i stereo camera and is also an \gls{ahrs}.
More information about the ZED 2i can be found in \cref{ssec:camera}.\\
Both sensors are connected to the computer via USB.
The specifications of each \gls{imu} can be read in \cref{tab:imu_datasheets}.
Because no information about the noise density or random walk of the myAHRS+ \gls{imu} could be found, a manual estimation of the error was done using the package \texttt{allan\_variance\_ros}~\footnote{\url{https://github.com/gaowenliang/imu_utils}}.
It analyzes the Allan variance from \gls{imu} measurement data recorded over a two-hour period, during which the \gls{imu} has not been moved.
The smaller values of the ZED 2i \gls{imu} indicate, that it is the better sensor.
\begin{table}[ht]
	\centering
	\caption{Comparison of the two used \glspl{imu} \cite{Withrobot2017, Stereolabs2019}}
	\label{tab:imu_datasheets}
	\begin{tabular}[t]{lccc}
		\toprule
		\textbf{Property}           & \textbf{myAHRS+} & \textbf{ZED 2i \gls{imu}} & \textbf{Unit}                                               \\
		\midrule
		Accelerometer range         & $\pm16$          & $\pm8$                    & \si{g}                                                      \\
		Gyroscope range             & $\pm2000$        & $\pm1000$                 & \si{\degree\per\second}                                     \\
		Magnetometer range          & $\pm1200$        & $\pm2500$                 & \si{\micro\tesla}                                           \\
		Rate                        & \SI{100}         & \SI{400}                  & \si{\hertz}                                                 \\
		Accelerometer noise density & \SI{4.502e-3}{}  & \SI{1.148e-3}{}           & \si{\frac{\metre}{\second\squared}\frac{1}{\sqrt{\hertz}}}  \\
		Accelerometer random walk   & \SI{7.337e-5}{}  & \SI{6.458e-5}{}           & \si{\frac{\metre}{\second\cubed}\frac{1}{\sqrt{\hertz}}}    \\
		Gyroscope noise density     & \SI{1.674e-4}{}  & \SI{8.254e-5}{}           & \si{\frac{\radian}{\second}\frac{1}{\sqrt{\hertz}}}         \\
		Gyroscope random walk       & \SI{5.042e-6}{}  & \SI{1.632e-7}{}           & \si{\frac{\radian}{\second\squared}\frac{1}{\sqrt{\hertz}}} \\
		\bottomrule
	\end{tabular}
\end{table}


\subsection{\glsentrytext{lidar}}
\begin{figure}[htbp]
	\centering
	\begin{subfigure}{0.3\textwidth}
		\centering
		\includegraphics[width=\textwidth]{Robosense.png}
		\caption{Robosense RS-Bpearl \cite{RoboSense2020}}
		\label{fig:lidar_robosense}
	\end{subfigure}
	% \hfill
	\begin{subfigure}{0.3\textwidth}
		\centering
		\includegraphics[width=\textwidth]{Velodyne.png}
		\caption{Velodyne Ultra puck \cite{Velodyne2018}}
		\label{fig:lidar_velodyne}
	\end{subfigure}
	\caption{The two used \glspl{lidar}}
	\label{fig:lidars_used}
\end{figure}
Two different \glspl{lidar} will be used during the experiment.
The RS-Bpearl and the Velodyne UltraPuck, see \cref{fig:lidars_used}.
The most relevant specifications of the two \glspl{lidar} can be seen in \cref{tab:lidar_datasheets}.
Both are mechanical \glspl{lidar} and have the same number of laser channels, but the Velodyne has a significant better vertical resolution, due to the smaller vertical \gls{fov}.
Both \glspl{lidar} need an external power supply and the data transfer to the pc is done via Ethernet connection.
Due to the setup of the test car it is only possible to mount one \gls{lidar} at a time.
\begin{table}[ht]
	\centering
	\caption{Comparison of the two used \acrshort{lidar}s \cite{RoboSense2020, Velodyne2018}}
	\label{tab:lidar_datasheets}
	\begin{tabular}[t]{lccc}
		\toprule
		\textbf{Property}     & \textbf{RS-Bpearl}   & \textbf{Velodyne Ultra Puck}    & \textbf{Unit}     \\
		\midrule
		Channels              & 32                   & 32                              &                   \\
		Points per second     & 576,000              & 600,000                         & \si{}             \\
		Laser wavelength      & \SI{905}{}           & \SI{903}{}                      & \si{\nano\metre}  \\
		Frame rate            & \SIrange{10}{20}{}   & \SIrange{5}{20}{}               & \si{\hertz}       \\
		Range                 & \SI{100}{}           & \SI{200}{}                      & \si{\metre}       \\
		Range accuracy        & $\pm\SI{3}{}$        & $\pm\SI{3}{}$                   & \si{\centi\metre} \\
		Horizontal \gls{fov}  & \SI{360}{}           & \SI{360}{}                      & \si{\degree}      \\
		Vertical \gls{fov}    & \SI{90}{}            & \SI{40}{} (\SIrange{-25}{15}{}) & \si{\degree}      \\
		Horizontal resolution & \SIrange{0.2}{0.4}{} & \SIrange{0.1}{0.4}{}            & \si{\degree}      \\
		Vertical resolution   & \SI{2.81}{}          & \SI{0.33}{}                     & \si{\degree}      \\
		\bottomrule
	\end{tabular}
\end{table}


\subsection{Camera}
\label{ssec:camera}
The ZED 2i camera from Stereolabs as seen in \cref{fig:imu_zed} will be used during the experiment to record the camera image.
The camera has two horizontally displaced lenses, allowing for stereo vision and thus also depth estimation.
A barometer, temperature sensor and an \gls{imu} are integrated as well.
It also provides many more features such as 3D positional tracking, mapping, object detection and point cloud generation.\\
The specifications of the camera can be seen in \cref{tab:camera_datasheet}.
For the recordings a resolution of 1280x720 at a frame rate of 30 fps is used.
\begin{table}[ht]
	\centering
	\caption{Specifications of the ZED 2i camera \cite{Stereolabs2019}}
	\label{tab:camera_datasheet}
	\begin{tabular}[t]{lccc}
		\toprule
		\textbf{Property}                          & \textbf{Value}                       & \textbf{Unit}       \\
		\midrule
		\multirow{4}{*}{Resolution (Side by side)} & 2 x (2208x1242)    @ \SI{15}{\hertz} & \multirow{4}{*}{px} \\
		                                           & 2 x (1920 x 1080) @ \SI{30}{\hertz}  &                     \\
		                                           & 2 x (1280 x 720) @ \SI{60}{\hertz}   &                     \\
		                                           & 2 x (672 x 376)   @ \SI{100}{\hertz} &                     \\
		Focal length                               & 2.12                                 & \si{\milli\metre}   \\
		\gls{fov}                                  & Max. 110 (H) x 70 (V) x 120 (D)      & \si{\degree}        \\
		Aperture                                   & f/1.8                                &                     \\
		
		\bottomrule
	\end{tabular}
\end{table}


\section{Sensor placement}
\begin{figure}[htpb]
	\centering
	\input{Graphics/TikZ/lidar_mount.tex}
	\caption{Mounting of the \acrshort{lidar}. Variable description in \cref{tab:lidar_mount}}
	\label{fig:tikz_lidar_mount}
\end{figure}
\begin{table}[htbp]
	\centering
	\caption{Some params}
	\label{tab:lidar_mount}
	\begin{tabular}[t]{clc}
		\toprule
		\textbf{Variable} & \textbf{Description}                                   & \textbf{Unit} \\
		\midrule
		$h_\mathrm{l} $   & \gls{lidar} height above ground                        & \si{\metre}   \\
		$d$               & Distance to ramp                                       & \si{\metre}   \\
		$h_\mathrm{r}$    & Height of ramp                                         & \si{\metre}   \\
		$l_\mathrm{w}$    & Light travel distance from ramp start to contact point & \si{\metre}   \\
		$d_\mathrm{w}$    & Distance from ramp start to contact point              & \si{\metre}   \\
		$\alpha$          & Ramp angle                                             & \si{\degree}  \\
		$\beta$           & \gls{lidar} mount angle                                & \si{\degree}  \\
		$\gamma$          & Laser line angle                                       & \si{\degree}  \\
		$\epsilon$        & \gls{lidar} vertical resolution                        & \si{\degree}  \\
		$n$               & Number of laser channels                               &               \\
		\bottomrule
	\end{tabular}
\end{table}
The \gls{imu} must be placed on a rigid point of the car, such that the \gls{imu}'s position always stays the same relative to the car.
Other than that it should also be placed in the transversal center of the car to guarantee that the centripetal acceleration is not skewed towards one side when driving around a corner.
The ZED 2i camera with the integrated \gls{imu} was placed on the roof of the car, because the camera images were used as well.
The myAHRS+ \gls{imu} was mounted on the floor of the car trunk.\\
The \gls{lidar} will be placed on top of the car, to get a greater \gls{fov}.
The pitch angle $\beta$ at which the \gls{lidar} will be mounted should be chosen such that the number of points in the area at the beginning of the ramp are maximized.
This allows for the most accurate distinction between planes of different inclination angles.
Because the distance to the ramp is not constant due to the movement of the car, the optimization can only be done for a specific distance.
The coordinates at which the lasers hit the ground and ramp depend on the height of the \gls{lidar} $h_\mathrm{l}$, the distance to the ramp $d$, the angle of the ramp $\alpha$, the angle $\beta$ at which the \gls{lidar} has been mounted on the car and finally on the vertical resolution $\epsilon$ and \gls{fov} of the \gls{lidar}.
The coordinates at which the laser lines of the \gls{lidar} hit the ground can be calculated in the following way.\\
The angle $\gamma$ between the plane parallel to the ground at \gls{lidar} height and each laser wave is defined as
\begin{equation}
	\gamma = \beta - i\epsilon
\end{equation}
with $i \in [0,1,2,\dots,n]$ being the laser channel ID starting from the lowest opening angle and going to the highest and $n$ being the number of laser channels.
On flat ground the distance at which the laser waves hit the ground can be calculated by
\begin{equation}
	d_\mathrm{hit,ground}  = \tan(\ang{90} - \gamma) h_\mathrm{l}.
	\label{eq:ground_points}
\end{equation}
With a ramp, the assumption from \cref{eq:ground_points} does not hold anymore.
The light does not travel as far.
The height above ground, when the light is at the beginning of the ramp can be calculated by
\begin{equation}
	h_\mathrm{w,start} = h_\mathrm{l} - d\tan(\gamma).
\end{equation}
The distance $l_\mathrm{w}$ which the light travels from the beginning of the ramp to the contact point with the ramp can be calculated using the law of sines
\begin{align}
	l_\mathrm{w} & = \frac{h_\mathrm{w,start} }{\sin(\alpha + \gamma)} \sin(\ang{90} - \alpha) \nonumber \\
	             & = -\frac{h_\mathrm{w,start} }{\sin(\alpha + \gamma)} \cos(\alpha).
\end{align}
The travelled distance along the x-axis from the start of the ramp to the contact point is then
\begin{align}
	d_\mathrm{w} & = l_\mathrm{w} \sin(\ang{90} - 2\alpha - \gamma) \nonumber \\
	             & = -l_\mathrm{w} \cos(2\alpha + \gamma)
\end{align}
Putting everything together, the total x distance from the \gls{lidar} to the contact point on the ramp can be calculated by
\begin{align}
	d_\mathrm{hit,ramp} & = d + d_\mathrm{w}                                                                                    \nonumber \\
	d_\mathrm{hit,ramp} & = d + \frac{h_\mathrm{l} - d\tan(\gamma)}{\sin(\alpha + \gamma)} \cos(\alpha) \cos(2\alpha + \gamma).
	\label{eq:final_equation}
\end{align}
Using \cref{eq:ground_points} and \cref{eq:final_equation} and optimizing $\beta$ such that the number of points in the area at the start of the ramp are maximized, the optimal mounting pitch angle $\beta$ for the two \glspl{lidar} has been found with $\beta_\mathrm{velodyne} = \ang{0}$ and $\beta_\mathrm{robos} = \ang{20}$.
The optimization was done for a distance of \SI{10}{\metre} to the ramp.
The angle between the two \glspl{lidar} differs due to the different starting opening angle of \SI{-25}{\degree} and \SI{0}{\degree} for the Velodyne and Robosense respectively, as well as due to the different vertical resolution.


\section{Car}
\label{sec:car}
The car used in the experiment is an eGolf 2017.
Being an electric car it provides better vibration properties than a car with an internal combustion engine, which means that the \gls{imu} measurements are less influenced by external noise.
The car has been "hacked" which allows among other things for the reading of the wheel ticks by tapping the signals from the CAN bus.
Unfortunately the wheel speed readings are only available in this "hacked" state, in which the output power of the motor is limited.
In this mode, the maximum speed is capped at \SI{5}{\kilo\metre\per\hour} and the power is not enough to allow for the traversing of ramps.
The car can only make it about halfway up.
Because of that, the normal mode was used to drive between different levels.
Before driving down, the mode was switched again to also provide the wheel speed measurements.
The car has a PC in the booth, at which all the sensors were connected to and which ran all the algorithms.
\iimprov{Text is bad e.g. "hacked" }
\missingfigure{Picture of eGolf}



\section{Garage}
\missingfigure{Picture of ramps and/or figure of ramps showing angles}
\itodo{Think of a good way to measure the true angle of the ramps}
\begin{figure}
	\begin{subfigure}{.3\linewidth}
		\centering
		\includegraphics[angle=-90, width=1\linewidth]{RampA.jpg}
		\caption{}
	\end{subfigure}
	\hfill
	\begin{subfigure}{.3\linewidth}
		\centering
		\includegraphics[angle=-90, width=1\linewidth]{RampB.jpg}
		\caption{}
	\end{subfigure}
	\hfill
	\begin{subfigure}{.3\linewidth}
		\centering
		\includegraphics[angle=-90, width=1\linewidth]{RampC.jpg}
		\caption{}
	\end{subfigure}
	\caption{All the ramps}
	\label{fig:all_ramps}
\end{figure}
